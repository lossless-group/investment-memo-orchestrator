# Changelog - 2025-11-26 (#1)

## Dataroom Analyzer Agent System & Export Improvements

### Overview
Introduced a new multi-agent dataroom analyzer system for processing investment datarooms, plus improvements to trademark handling and export versioning.

---

## New Feature: Dataroom Analyzer

### Purpose
Analyze investment datarooms containing diverse document types (pitch decks, financials, legal docs, competitive analysis, etc.) and produce structured inventory with intelligent classification.

### Architecture

Created new module at `src/agents/dataroom/` with 5 files:

```
src/agents/dataroom/
â”œâ”€â”€ __init__.py              # Package exports
â”œâ”€â”€ analyzer.py              # Main orchestrator (8.9 KB)
â”œâ”€â”€ dataroom_state.py        # TypedDict schemas (11 KB)
â”œâ”€â”€ document_scanner.py      # Directory scanning (6.7 KB)
â”œâ”€â”€ document_classifier.py   # 3-stage classification (17 KB)
â””â”€â”€ extractors/              # Placeholder for Phase 2
    â””â”€â”€ __init__.py
```

### Three-Stage Classification System

The classifier uses a hierarchical approach for maximum accuracy:

**Stage 1: Directory-Based (Highest Confidence)**
- Parses directory names like `"1 1_0 Executive Summary"` or `"4 4_0 GTM_Competitive Overview"`
- Strips numeric prefixes and normalizes separators
- Maps to document types with 85-90% confidence

**Stage 2: Filename Pattern Matching**
- Regex patterns for common naming conventions
- Examples: `"cap.*table"` â†’ cap_table, `"battlecard"` â†’ competitive_analysis
- Confidence based on match specificity (60-85%)

**Stage 3: LLM Content Classification (Optional)**
- Uses Claude Sonnet for uncertain documents
- Extracts content samples (first 2000 chars)
- Only invoked when earlier stages have <70% confidence

### Document Type Taxonomy

Priority 1 (Critical):
- `pitch_deck` - Investor presentations, executive summaries
- `competitive_analysis` - Battlecards, competitor comparisons, market maps
- `financial_statements` - P&L, balance sheets, historical financials
- `financial_projections` - Operating models, forecasts, budgets
- `cap_table` - Ownership structure, equity breakdown

Priority 2 (Important):
- `term_sheet` - Investment terms, SAFE notes
- `team_bios` - Founder/leadership backgrounds
- `customer_list` - Notable customers, case studies
- `traction_metrics` - KPIs, growth data

Priority 3 (Supporting):
- `product_documentation` - Architecture, specs, roadmaps
- `marketing_collateral` - Datasheets, brochures
- `legal_document` - Corporate docs, agreements
- `investor_update` - Board materials, governance

### TypedDict Schemas

Defined 11 structured schemas in `dataroom_state.py`:

- `DocumentInventoryItem` - Individual document metadata
- `FinancialData` - Income statement, balance sheet, metrics
- `CapTableData` - Shareholders, options pool, SAFEs
- `CompetitiveData` - Competitors, positioning, SWOT
- `TeamData` - Founders, leadership, advisors
- `TractionData` - Customers, revenue, pipeline
- `LegalDocData` - Term sheets, investment terms
- `DataroomAnalysis` - Main analysis output container

### Output Artifacts

Follows project conventions with versioned output:

```
output/Hydden-v0.0.1/
â”œâ”€â”€ 0-dataroom-analysis.json  # Structured inventory (14 KB)
â””â”€â”€ 0-dataroom-analysis.md    # Human-readable report (4.3 KB)
```

**Markdown Report Includes:**
- Document inventory summary by type
- Detailed document list with confidence indicators (ðŸŸ¢/ðŸŸ¡/ðŸ”´)
- File sizes, page counts, classification reasoning
- Data gaps (missing document types)
- Processing notes

### Usage

```bash
# CLI usage
python -m src.agents.dataroom.analyzer "path/to/dataroom" "Company Name"

# Programmatic usage
from src.agents.dataroom import analyze_dataroom
analysis = analyze_dataroom("path/to/dataroom", "Company Name")
```

### Testing Results

Tested on Hydden dataroom (20 documents):
- **Classification accuracy**: 100% (all 20 documents correctly typed)
- **High confidence**: 20/20 documents (100%)
- **Processing time**: 0.1 seconds
- **Data gaps identified**: Missing team_bios, financial_statements

---

## Improvement: Trademark Path Handling

### Problem
Trademark paths in company JSON files were being malformed when using absolute paths:
```
# Before (broken)
![Logo](../..//Users/mpstaton/code/.../logo.svg)
```

### Solution
Updated `src/agents/trademark_enrichment.py` to properly handle:
- **HTTP/HTTPS URLs**: Pass through unchanged
- **Absolute paths**: Convert to relative from project root
- **Relative paths**: Prepend `../../` correctly for output directory navigation

```python
# Now supports clean relative paths in data/*.json
"trademark_light": "data/Secure-Inputs/trademark__OWM--Light-Mode.svg"
```

### Files Modified
- `src/agents/trademark_enrichment.py` (+15 lines)

---

## Improvement: Export Auto-Versioning

### Problem
Running export multiple times would overwrite the same HTML file.

### Solution
Added automatic versioning to `cli/export_branded.py`:
- Detects if output file exists
- Appends `.1`, `.2`, etc. to filename
- Supports 4-segment versioning (e.g., `OWM-v0.0.2.1.html`)

```bash
# First export
OWM-v0.0.2.html

# Subsequent exports
OWM-v0.0.2.1.html
OWM-v0.0.2.2.html
```

### Files Modified
- `cli/export_branded.py` (+11 lines)

---

## Planning Document

Created comprehensive planning document for the dataroom analyzer system:
- `context-vigilance/Dataroom-Analyzer-Agent-Plan.md`
- Includes architecture, classification strategies, implementation phases
- Updated based on real Hydden dataroom analysis

---

## Files Changed Summary

### New Files (6)
| File | Size | Purpose |
|------|------|---------|
| `src/agents/dataroom/__init__.py` | 774 B | Package exports |
| `src/agents/dataroom/analyzer.py` | 8.9 KB | Main orchestrator |
| `src/agents/dataroom/dataroom_state.py` | 11 KB | TypedDict schemas |
| `src/agents/dataroom/document_scanner.py` | 6.7 KB | Directory scanning |
| `src/agents/dataroom/document_classifier.py` | 17 KB | 3-stage classification |
| `src/agents/dataroom/extractors/__init__.py` | ~100 B | Placeholder |

### Modified Files (2)
| File | Changes | Purpose |
|------|---------|---------|
| `src/agents/trademark_enrichment.py` | +15 lines | Fix path handling |
| `cli/export_branded.py` | +11 lines | Auto-versioning |

### Documentation (1)
| File | Size | Purpose |
|------|------|---------|
| `context-vigilance/Dataroom-Analyzer-Agent-Plan.md` | ~15 KB | Design document |

---

## Next Steps (Phase 2)

The dataroom analyzer foundation is complete. Future phases:

1. **Document Extractors** - Build type-specific extractors:
   - `competitive_extractor.py` - Parse battlecards, synthesize competitive landscape
   - `financial_extractor.py` - Extract P&L, projections, metrics
   - `cap_table_extractor.py` - Parse ownership structure

2. **Data Synthesis** - Cross-document fact extraction and conflict resolution

3. **Workflow Integration** - Connect to main memo generation pipeline

---

## Testing & Validation

### Dataroom Analyzer
- âœ… Scans directories recursively
- âœ… Handles numbered directory patterns (`N N_0 Category Name`)
- âœ… Classifies with 3-stage confidence system
- âœ… Outputs to versioned `output/` directory
- âœ… Generates both JSON and markdown artifacts
- âœ… Identifies data gaps

### Export Improvements
- âœ… Trademark relative paths work correctly
- âœ… Auto-versioning prevents overwrites
- âœ… Both light and dark mode exports working

---

## Contributors

Implementation by Claude Code (Anthropic) with user guidance.
